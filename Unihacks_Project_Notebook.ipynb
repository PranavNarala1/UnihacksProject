{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unihacks_Project_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EBHzHR7YT9Q"
      },
      "outputs": [],
      "source": [
        "#!unzip CocoCarDamageDataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "TVmWQRCPctDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []"
      ],
      "metadata": {
        "id": "S4Ez6c7AdycJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_json_data = open('/content/train/COCO_mul_train_annos.json')\n",
        "train_json_data = json.load(train_json_data)\n",
        "for image in train_json_data['images']:\n",
        "  file_name = image['file_name']\n",
        "  id = image['id']\n",
        "  img = cv2.imread(f'/content/train/{file_name}')\n",
        "  img = cv2.resize(img, (500, 500))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img = img / 255\n",
        "  x_train.append(img)\n",
        "  y_train_value = [0,0,0,0,0]\n",
        "  for annotation in train_json_data['annotations']:\n",
        "    if annotation['image_id'] == id:\n",
        "      y_train_value[int(annotation['category_id']) - 1] = 1\n",
        "  y_train.append(y_train_value)\n",
        "\n",
        "\n",
        "test_json_data = open('/content/val/COCO_mul_val_annos.json')\n",
        "test_json_data = json.load(test_json_data)\n",
        "for image in test_json_data['images']:\n",
        "  file_name = image['file_name']\n",
        "  id = image['id']\n",
        "  img = cv2.imread(f'/content/val/{file_name}')\n",
        "  img = cv2.resize(img, (500, 500))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img = img / 255\n",
        "  x_test.append(img)\n",
        "  y_test_value = [0,0,0,0,0]\n",
        "  for annotation in test_json_data['annotations']:\n",
        "    if annotation['image_id'] == id:\n",
        "      y_test_value[int(annotation['category_id']) - 1] = 1\n",
        "  y_test.append(y_test_value)"
      ],
      "metadata": {
        "id": "ynaxIVnOgkwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)"
      ],
      "metadata": {
        "id": "At9b51mu-v4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = keras.models.Sequential([ #headlamp\n",
        "      keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(500,500,1)),\n",
        "      keras.layers.MaxPool2D(),\n",
        "      keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "      keras.layers.MaxPool2D(),\n",
        "      keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(300, activation='relu'),\n",
        "      keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    #keras.layers.Flatten(),\n",
        "    #keras.layers.Dense(25, activation=\"swish\"),\n",
        "    #keras.layers.Dense(25, activation=\"swish\"),\n",
        "    #keras.layers.Dense(25, activation=\"swish\"),\n",
        "    #keras.layers.Dense(25, activation=\"swish\"),\n",
        "    #keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model1.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "YbJcq7Go9SVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.models.Sequential([ #rearbumper\n",
        "      keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(500,500,1)),\n",
        "      keras.layers.MaxPool2D(),\n",
        "      keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "      keras.layers.MaxPool2D(),\n",
        "      keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(300, activation='relu'),\n",
        "      keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    # keras.layers.Flatten(),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model2.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "2m8zfyTHVQEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = keras.models.Sequential([ #door\n",
        "     keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(500,500,1)),\n",
        "     keras.layers.MaxPool2D(),\n",
        "     keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "     keras.layers.MaxPool2D(),\n",
        "     keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "     keras.layers.Flatten(),\n",
        "     keras.layers.Dense(300, activation='relu'),\n",
        "     keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    # keras.layers.Flatten(),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model3.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "pbH0-jFgVSat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = keras.models.Sequential([ #hood\n",
        "     keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(500,500,1)),\n",
        "     keras.layers.MaxPool2D(),\n",
        "     keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "     keras.layers.MaxPool2D(),\n",
        "     keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "     keras.layers.Flatten(),\n",
        "     keras.layers.Dense(300, activation='relu'),\n",
        "     keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    # keras.layers.Flatten(),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model4.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "YoMlvKSwVT84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = keras.models.Sequential([ #front bumper\n",
        "     keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(500,500,1)),\n",
        "     keras.layers.MaxPool2D(),\n",
        "     keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "     keras.layers.MaxPool2D(),\n",
        "     keras.layers.Conv2D(32, kernel_size=3, activation='relu'),\n",
        "     keras.layers.Flatten(),\n",
        "     keras.layers.Dense(300, activation='relu'),\n",
        "     keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    # keras.layers.Flatten(),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(25, activation=\"swish\"),\n",
        "    # keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model5.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "o8JUy3jqVVj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(x_train, np.asarray([y_train[n][0] for n in range(y_train.size // 5)]), epochs = 10, validation_data = (x_test, np.asarray([y_test[n][0] for n in range(y_test.size // 5)])))\n",
        "model2.fit(x_train, np.asarray([y_train[n][1] for n in range(y_train.size // 5)]), epochs = 10, validation_data = (x_test, np.asarray([y_test[n][1] for n in range(y_test.size // 5)])))\n",
        "model3.fit(x_train, np.asarray([y_train[n][2] for n in range(y_train.size // 5)]), epochs = 10, validation_data = (x_test, np.asarray([y_test[n][2] for n in range(y_test.size // 5)])))\n",
        "model4.fit(x_train, np.asarray([y_train[n][3] for n in range(y_train.size // 5)]), epochs = 10, validation_data = (x_test, np.asarray([y_test[n][3] for n in range(y_test.size // 5)])))\n",
        "model5.fit(x_train, np.asarray([y_train[n][4] for n in range(y_train.size // 5)]), epochs = 10, validation_data = (x_test, np.asarray([y_test[n][4] for n in range(y_test.size // 5)])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Vskhjx9e2O",
        "outputId": "53e1bf3c-a356-444b-b8d8-c604a3ace566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 29s 9s/step - loss: 7.6286 - accuracy: 0.4915 - val_loss: 6.5145 - val_accuracy: 0.9091\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 20s 10s/step - loss: 7.9493 - accuracy: 0.7966 - val_loss: 0.6932 - val_accuracy: 0.9091\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 18s 9s/step - loss: 1.7441 - accuracy: 0.5763 - val_loss: 1.3430 - val_accuracy: 0.0909\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 17s 8s/step - loss: 0.5897 - accuracy: 0.5763 - val_loss: 0.4987 - val_accuracy: 0.9091\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 17s 8s/step - loss: 0.6695 - accuracy: 0.7966 - val_loss: 0.4421 - val_accuracy: 0.9091\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 17s 8s/step - loss: 0.4665 - accuracy: 0.7966 - val_loss: 0.3531 - val_accuracy: 0.9091\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 17s 8s/step - loss: 0.3179 - accuracy: 0.8475 - val_loss: 0.3505 - val_accuracy: 0.9091\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 17s 8s/step - loss: 0.2544 - accuracy: 0.8983 - val_loss: 0.3755 - val_accuracy: 0.8182\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 17s 8s/step - loss: 0.2291 - accuracy: 0.9153 - val_loss: 0.3047 - val_accuracy: 0.9091\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 17s 8s/step - loss: 0.1647 - accuracy: 0.9492 - val_loss: 0.2746 - val_accuracy: 0.9091\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 284ms/step - loss: 1.5755 - accuracy: 0.3390 - val_loss: 0.8242 - val_accuracy: 0.3636\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.7693 - accuracy: 0.4915 - val_loss: 1.4304 - val_accuracy: 0.5455\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.7840 - accuracy: 0.6441 - val_loss: 1.6289 - val_accuracy: 0.5455\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.9773 - accuracy: 0.5254 - val_loss: 0.5457 - val_accuracy: 0.8182\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.7516 - accuracy: 0.6441 - val_loss: 0.7315 - val_accuracy: 0.6364\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.9940 - accuracy: 0.5424 - val_loss: 0.7018 - val_accuracy: 0.6364\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.9113 - accuracy: 0.6780 - val_loss: 0.4263 - val_accuracy: 0.7273\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.6521 - accuracy: 0.6441 - val_loss: 0.4865 - val_accuracy: 0.6364\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.7188 - accuracy: 0.7288 - val_loss: 1.0213 - val_accuracy: 0.6364\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.3608 - accuracy: 0.7966 - val_loss: 0.7988 - val_accuracy: 0.5455\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 262ms/step - loss: 5.3313 - accuracy: 0.4068 - val_loss: 43.0627 - val_accuracy: 0.1818\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 25.9540 - accuracy: 0.4576 - val_loss: 33.4441 - val_accuracy: 0.1818\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 14.3853 - accuracy: 0.4576 - val_loss: 2.6066 - val_accuracy: 0.8182\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 6.7395 - accuracy: 0.5424 - val_loss: 4.9798 - val_accuracy: 0.8182\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 7.6040 - accuracy: 0.5424 - val_loss: 1.1149 - val_accuracy: 0.8182\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 2.2245 - accuracy: 0.5254 - val_loss: 10.1424 - val_accuracy: 0.1818\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 5.6170 - accuracy: 0.4576 - val_loss: 6.8372 - val_accuracy: 0.1818\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 2.3110 - accuracy: 0.5593 - val_loss: 2.0313 - val_accuracy: 0.8182\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 3.2001 - accuracy: 0.5424 - val_loss: 2.8754 - val_accuracy: 0.8182\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 3.1389 - accuracy: 0.5424 - val_loss: 1.3773 - val_accuracy: 0.6364\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 267ms/step - loss: 1.9409 - accuracy: 0.4576 - val_loss: 6.6850 - val_accuracy: 0.5455\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 3.1332 - accuracy: 0.6271 - val_loss: 0.4979 - val_accuracy: 0.7273\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.7189 - accuracy: 0.7288 - val_loss: 5.5001 - val_accuracy: 0.4545\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 3.2606 - accuracy: 0.5424 - val_loss: 5.9869 - val_accuracy: 0.5455\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 3.1100 - accuracy: 0.5932 - val_loss: 2.5107 - val_accuracy: 0.5455\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 2.1319 - accuracy: 0.5254 - val_loss: 0.6814 - val_accuracy: 0.6364\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.9584 - accuracy: 0.7458 - val_loss: 3.3412 - val_accuracy: 0.5455\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1.3530 - accuracy: 0.6780 - val_loss: 2.2522 - val_accuracy: 0.7273\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.7271 - accuracy: 0.6271 - val_loss: 0.8366 - val_accuracy: 0.7273\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.4730 - accuracy: 0.8475 - val_loss: 3.3330 - val_accuracy: 0.5455\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 269ms/step - loss: 24.9206 - accuracy: 0.5593 - val_loss: 8.8318 - val_accuracy: 0.5455\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 9.3105 - accuracy: 0.5254 - val_loss: 8.9511 - val_accuracy: 0.5455\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 6.2000 - accuracy: 0.5254 - val_loss: 0.6973 - val_accuracy: 0.5455\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.0882 - accuracy: 0.5932 - val_loss: 0.7476 - val_accuracy: 0.6364\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 1.9431 - accuracy: 0.4237 - val_loss: 2.3281 - val_accuracy: 0.5455\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 1.9068 - accuracy: 0.5763 - val_loss: 1.9121 - val_accuracy: 0.4545\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 1.4679 - accuracy: 0.6102 - val_loss: 0.8887 - val_accuracy: 0.5455\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1.2607 - accuracy: 0.6780 - val_loss: 0.2793 - val_accuracy: 0.9091\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.6861 - accuracy: 0.7119 - val_loss: 0.9296 - val_accuracy: 0.6364\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.7123 - accuracy: 0.7119 - val_loss: 0.3536 - val_accuracy: 0.8182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f723e34fe10>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(x_test, np.asarray([y_test[n][0] for n in range(y_test.size // 5)]))\n",
        "model2.evaluate(x_test, np.asarray([y_test[n][1] for n in range(y_test.size // 5)]))\n",
        "model3.evaluate(x_test, np.asarray([y_test[n][2] for n in range(y_test.size // 5)]))\n",
        "model4.evaluate(x_test, np.asarray([y_test[n][3] for n in range(y_test.size // 5)]))\n",
        "model5.evaluate(x_test, np.asarray([y_test[n][4] for n in range(y_test.size // 5)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYLJNnXa9jsE",
        "outputId": "5e6343d0-8403-46d8-c345-38ab3df6c680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2746 - accuracy: 0.9091\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7988 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3773 - accuracy: 0.6364\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.3330 - accuracy: 0.5455\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3536 - accuracy: 0.8182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3536092936992645, 0.8181818127632141]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model1.predict(x_train)\n",
        "#model2.predict(x_train)\n",
        "#model3.predict(x_train)\n",
        "model4.predict(x_train)\n",
        "#model5.predict(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4BWj2SSFNcf",
        "outputId": "f5a63daa-f8fe-4ed7-f07e-d8014e2fb929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.3561072e-04],\n",
              "       [1.5436797e-09],\n",
              "       [4.3044090e-03],\n",
              "       [1.2447870e-06],\n",
              "       [2.5353516e-11],\n",
              "       [2.4115283e-07],\n",
              "       [9.9690514e-09],\n",
              "       [1.6462803e-04],\n",
              "       [1.6130606e-09],\n",
              "       [9.8680586e-02],\n",
              "       [9.8620612e-06],\n",
              "       [9.2047453e-04],\n",
              "       [7.2524977e-01],\n",
              "       [1.9531846e-03],\n",
              "       [1.8764099e-01],\n",
              "       [4.1095763e-01],\n",
              "       [1.0362985e-09],\n",
              "       [6.4276719e-01],\n",
              "       [7.4713993e-01],\n",
              "       [1.6777560e-01],\n",
              "       [2.5919794e-10],\n",
              "       [3.6302209e-04],\n",
              "       [1.7265379e-03],\n",
              "       [8.2133538e-06],\n",
              "       [3.4528170e-05],\n",
              "       [8.0154168e-09],\n",
              "       [4.5621395e-04],\n",
              "       [1.7982721e-04],\n",
              "       [2.9042573e-07],\n",
              "       [7.3447752e-01],\n",
              "       [9.2133343e-02],\n",
              "       [7.2524977e-01],\n",
              "       [5.6270832e-10],\n",
              "       [2.7237660e-05],\n",
              "       [9.9740136e-01],\n",
              "       [9.5759928e-02],\n",
              "       [6.1738652e-01],\n",
              "       [2.7884739e-06],\n",
              "       [1.1161566e-03],\n",
              "       [4.4423307e-10],\n",
              "       [5.2569419e-01],\n",
              "       [1.0819290e-10],\n",
              "       [2.0721040e-09],\n",
              "       [7.9432935e-02],\n",
              "       [2.8575361e-03],\n",
              "       [9.9776303e-09],\n",
              "       [5.1251054e-04],\n",
              "       [9.6311494e-05],\n",
              "       [4.9068996e-05],\n",
              "       [3.2151857e-07],\n",
              "       [2.7893902e-05],\n",
              "       [2.0485816e-08],\n",
              "       [8.6347018e-06],\n",
              "       [1.3509752e-08],\n",
              "       [2.9895335e-02],\n",
              "       [9.1466099e-02],\n",
              "       [1.2792791e-06],\n",
              "       [1.6409159e-04],\n",
              "       [8.6644471e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('model1')\n",
        "model2.save('model2')\n",
        "model3.save('model3')\n",
        "model4.save('model4')\n",
        "model5.save('model5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jce3nMXu_otG",
        "outputId": "b9d92e08-079a-4d21-ef33-304bde0d5543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model1/assets\n",
            "INFO:tensorflow:Assets written to: model2/assets\n",
            "INFO:tensorflow:Assets written to: model3/assets\n",
            "INFO:tensorflow:Assets written to: model4/assets\n",
            "INFO:tensorflow:Assets written to: model5/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/test/12.jpg')\n",
        "img = cv2.resize(img, (500, 500))\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = img / 255\n",
        "model1.predict(np.array([img]))[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG8c7UVrIo2-",
        "outputId": "faa641e7-0bdf-420b-cce9-4ed638fc62a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.765447"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(img_input):\n",
        "  img = img_input\n",
        "  img = cv2.resize(img, (500, 500))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img = img / 255\n",
        "  prediction1 = model1.predict(np.array([img]))[0][0]\n",
        "  prediction2 = model2.predict(np.array([img]))[0][0]\n",
        "  prediction3 = model3.predict(np.array([img]))[0][0]\n",
        "  prediction4 = model4.predict(np.array([img]))[0][0]\n",
        "  prediction5 = model5.predict(np.array([img]))[0][0]\n",
        "\n",
        "  if (prediction1 < 0.10):\n",
        "    prediction1 *= 100\n",
        "  elif (prediction1 < 0.20):\n",
        "    prediction1 *= 160\n",
        "  elif (prediction1 < 0.30):\n",
        "    prediction1 *= 220\n",
        "  elif (prediction1 < 0.40):\n",
        "    prediction1 *= 280\n",
        "  elif (prediction1 < 0.50):\n",
        "    prediction1 *= 360\n",
        "  elif (prediction1 < 0.60):\n",
        "    prediction1 *= 420\n",
        "  elif (prediction1 < 0.70):\n",
        "    prediction1 *= 520\n",
        "  elif (prediction1 < 0.80):\n",
        "    prediction1 *= 640\n",
        "  elif (prediction1 < 0.90):\n",
        "    prediction1 *= 670\n",
        "  else:\n",
        "    prediction1 *= 700\n",
        "\n",
        "  if (prediction2 < 0.10):\n",
        "    prediction2 *= 300\n",
        "  elif (prediction2 < 0.20):\n",
        "    prediction2 *= 420\n",
        "  elif (prediction2 < 0.30):\n",
        "    prediction2 *= 540\n",
        "  elif (prediction2 < 0.40):\n",
        "    prediction2 *= 660\n",
        "  elif (prediction2 < 0.50):\n",
        "    prediction2 *= 780\n",
        "  elif (prediction2 < 0.60):\n",
        "    prediction2 *= 900\n",
        "  elif (prediction2 < 0.70):\n",
        "    prediction2 *= 1200\n",
        "  elif (prediction2 < 0.80):\n",
        "    prediction2 *= 1400\n",
        "  elif (prediction2 < 0.90):\n",
        "    prediction2 *= 1600\n",
        "  else:\n",
        "    prediction2 *= 2000\n",
        "\n",
        "  if (prediction3 < 0.10):\n",
        "    prediction3 *= 150\n",
        "  elif (prediction3 < 0.20):\n",
        "    prediction3 *= 200\n",
        "  elif (prediction3 < 0.30):\n",
        "    prediction3 *= 350\n",
        "  elif (prediction3 < 0.40):\n",
        "    prediction3 *= 600\n",
        "  elif (prediction3 < 0.50):\n",
        "    prediction3 *= 700\n",
        "  elif (prediction3 < 0.60):\n",
        "    prediction3 *= 800\n",
        "  elif (prediction3 < 0.70):\n",
        "    prediction3 *= 900\n",
        "  elif (prediction3 < 0.80):\n",
        "    prediction3 *= 1000\n",
        "  elif (prediction3 < 0.90):\n",
        "    prediction3 *= 1250\n",
        "  else:\n",
        "    prediction3 *= 1500\n",
        "\n",
        "  if (prediction4 < 0.10):\n",
        "    prediction4 *= 700\n",
        "  elif (prediction4 < 0.20):\n",
        "    prediction4 *= 820\n",
        "  elif (prediction4 < 0.30):\n",
        "    prediction4 *= 940\n",
        "  elif (prediction4 < 0.40):\n",
        "    prediction4 *= 1060\n",
        "  elif (prediction4 < 0.50):\n",
        "    prediction4 *= 1180\n",
        "  elif (prediction4 < 0.60):\n",
        "    prediction4 *= 1300\n",
        "  elif (prediction4 < 0.70):\n",
        "    prediction4 *= 1450\n",
        "  elif (prediction4 < 0.80):\n",
        "    prediction4 *= 1600\n",
        "  elif (prediction4 < 0.90):\n",
        "    prediction4 *= 1750\n",
        "  else:\n",
        "    prediction4 *= 1900\n",
        "\n",
        "  if (prediction5 < 0.10):\n",
        "    prediction5 *= 300\n",
        "  elif (prediction5 < 0.20):\n",
        "    prediction5 *= 420\n",
        "  elif (prediction5 < 0.30):\n",
        "    prediction5 *= 540\n",
        "  elif (prediction5 < 0.40):\n",
        "    prediction5 *= 660\n",
        "  elif (prediction5 < 0.50):\n",
        "    prediction5 *= 360\n",
        "  elif (prediction5 < 0.60):\n",
        "    prediction5 *= 900\n",
        "  elif (prediction5 < 0.70):\n",
        "    prediction5 *= 1200\n",
        "  elif (prediction5 < 0.80):\n",
        "    prediction5 *= 1400\n",
        "  elif (prediction5 < 0.90):\n",
        "    prediction5 *= 1600\n",
        "  else:\n",
        "    prediction5 *= 2000\n",
        "\n",
        "  total = prediction1 + prediction2 + prediction3 + prediction4 + prediction5\n",
        "  return total"
      ],
      "metadata": {
        "id": "GUb0vn-oFifk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/val/9.jpg')\n",
        "print('Estimated repair cost: ' + str(test(img)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27OfnhtZHCjA",
        "outputId": "265cae04-ef96-4b41-f774-18e109ac5667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated repair cost: 1659.789167046547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources:\n",
        "\n",
        "Dataset - https://www.kaggle.com/lplenka/coco-car-damage-detection-dataset"
      ],
      "metadata": {
        "id": "U_5Qz3WnYxur"
      }
    }
  ]
}